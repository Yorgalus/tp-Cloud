# üßë‚Äçüè´ Pr√©sentation ‚Äì D√©ploiement OpenNebula & Configuration R√©seau

---

## üåê Partie R√©seau ‚Äì Mise en place de l‚Äôenvironnement

Tout d'abord, on a commenc√© par **configurer les interfaces r√©seau des VMs**.

### üîß Adaptateurs r√©seau

Chaque VM est configur√©e avec :
- Un **adaptateur NAT** pour acc√©der √† Internet
- Un **r√©seau priv√© h√¥te** nomm√© `TP_Leo` pour la communication interne

---

### üìÅ Fichier de configuration de la 3e interface (`enp0s8`)

Sur chaque VM, on a ajout√© la config suivante :

```
DEVICE=enp0s8
BOOTPROTO=static
ONBOOT=yes
IPADDR=10.3.1.10
NETMASK=255.255.255.0
```
---

## üì° Configuration IP & V√©rification R√©seau

Ensuite, on ajuste les IP selon la machine :
```
| Machine        | IP           |
|----------------|--------------|
| `frontend.one` | `10.3.1.10`  |
| `kvm1.one`     | `10.3.1.11`  |
| `kvm2.one`     | `10.3.1.12`  |
```
---

### ‚úÖ V√©rification de connectivit√© ‚Äì Ping

#### üîÅ Depuis `kvm1.one` vers `frontend.one`
```
- ping frontend.one
```
**R√©sultat :**
```
- 4 packets transmitted, 4 received, 0% packet loss  
- rtt min/avg/max = ~0.8 to 1.3 ms
```
---

#### üîÅ Depuis `kvm2.one` vers `frontend.one`
```
- ping frontend.one
```
**R√©sultat :**
```
- 4 packets transmitted, 4 received, 0% packet loss  
- rtt min/avg/max = ~0.89 to 1.17 ms
```
‚úÖ **R√©seau fonctionnel et machines joignables !**

---

## üõ¢Ô∏è Partie Base de Donn√©es ‚Äì MySQL

L‚Äôobjectif ici √©tait d‚Äôinstaller **MySQL 8**, requis par OpenNebula.

---

### üì¶ √âtapes d'installation

#### 1. Ajout du d√©p√¥t MySQL
```
- wget https://dev.mysql.com/get/mysql80-community-release-el9-5.noarch.rpm  
- rpm -ivh mysql80-community-release-el9-5.noarch.rpm
```
#### 2. Installation du serveur
```
- dnf install mysql-community-server
```
---

### ‚öôÔ∏è D√©marrage et Configuration

#### D√©marrage du service MySQL
```
- systemctl start mysqld  
- systemctl enable mysqld
```
#### Configuration des utilisateurs MySQL
```
- ALTER USER 'root'@'localhost' IDENTIFIED BY 'mangemonSQL1234*';  
- CREATE USER 'oneadmin' IDENTIFIED BY 'mangemondeuxiemeSQL1234*';  
- CREATE DATABASE opennebula;  
- GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin';  
- SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;
```



keyket1234
mysql: mangemonSQL1234*
mangemondeuxiemeSQL1234*
---

## ‚òÅÔ∏è Partie OpenNebula ‚Äì Installation

### üóÇÔ∏è Ajout du d√©p√¥t OpenNebula

Cr√©er le fichier `/etc/yum.repos.d/opennebula.repo` :

```
[opennebula] name=OpenNebula Community Edition baseurl=https://downloads.opennebula.io/repo/6.10/RedHat/$releasever/$basearch enabled=1 gpgkey=https://downloads.opennebula.io/repo/repo2.key gpgcheck=1 repo_gpgcheck=1
```

Puis mettre en cache les m√©tadonn√©es :
```
- dnf makecache -y
```
---

### üß∞ Installation OpenNebula
```
- dnf install opennebula opennebula-sunstone opennebula-fireedge
```
---

### üõ†Ô∏è Configuration de la base de donn√©es

Modifier le fichier `/etc/one/oned.conf` avec les bonnes infos MySQL :
```
DB = [ BACKEND = "mysql", SERVER = "localhost", USER = "oneadmin", PASSWD = "also_here_define_another_strong_password", DB_NAME = "opennebula" ]
```

---

### üë§ Authentification Web UI

Cr√©er le fichier `.one_auth` pour l‚Äôutilisateur :
```
- echo "toto:a" > /var/lib/one/.one/one_auth
```
‚ö†Ô∏è Ce fichier doit appartenir √† l‚Äôutilisateur `oneadmin`.

---

### üöÄ D√©marrage des services OpenNebula
```
- systemctl start opennebula opennebula-sunstone  
- systemctl enable opennebula opennebula-sunstone
```
---

## üî• Configuration Syst√®me ‚Äì Firewall

Ouverture des ports n√©cessaires :
```
 firewall-cmd --permanent --add-port=9869/tcp    # WebUI (Sunstone)  
 firewall-cmd --permanent --add-port=22/tcp      # SSH  
 firewall-cmd --permanent --add-port=2633/tcp    # XML-RPC API  
 firewall-cmd --permanent --add-port=4124/tcp    # Monitoring TCP  
 firewall-cmd --permanent --add-port=4124/udp    # Monitoring UDP  
 firewall-cmd --permanent --add-port=29876/tcp   # NoVNC proxy  
 firewall-cmd --reload
```
---

## üß™ Test Final ‚Äì Acc√®s WebUI

‚û°Ô∏è Acc√©der √† l'interface web :

[http://10.3.1.11:9869](http://10.3.1.11:9869)

**Identifiants de connexion :**

- **Login** : `toto`  
- **Mot de passe** : `a`

‚úÖ Interface fonctionnelle et acc√®s confirm√© !

---
# II.2. Noeuds KVM

Cette partie a √©t√© r√©alis√©e sur `kvm1.one` en premier. Une fois que tout fonctionne, le m√™me processus peut √™tre r√©p√©t√© pour ajouter le deuxi√®me n≈ìud dans la partie IV. du TP.

---

## A. KVM

### üåû Ajouter des d√©p√¥ts suppl√©mentaires

1. Ajout des d√©p√¥ts **OpenNebula** :

   Le d√©p√¥t OpenNebula a √©t√© ajout√© √† `/etc/yum.repos.d/opennebula.repo` :
```
   - `[opennebula]`
   - `name=OpenNebula Community Edition`
   - `baseurl=https://downloads.opennebula.io/repo/6.10/RedHat/$releasever/$basearch`
   - `enabled=1`
   - `gpgkey=https://downloads.opennebula.io/repo/repo2.key`
   - `gpgcheck=1`
   - `repo_gpgcheck=1`
```
2. Ajout des d√©p√¥ts MySQL communautaire :

   Le RPM MySQL a √©t√© t√©l√©charg√© et install√© :
```
   - `wget https://dev.mysql.com/get/mysql80-community-release-el9-5.noarch.rpm`
   - `rpm -ivh mysql80-community-release-el9-5.noarch.rpm`
```
3. Ajout des d√©p√¥ts **EPEL** sur **Rocky Linux** :
```
   - `dnf install -y epel-release`
```
### üåû Installer les libs MySQL

Installation de MySQL Community Server :
```
- `dnf install -y mysql-community-server`
```
Retour de la commande :
```
- `Last metadata expiration check: 0:03:29 ago on Fri Apr 6 11:18:43 2025.`
- `Dependencies resolved.`
- `========================================================================================`
- ` Package                       Arch   Version                           Repository    Size`
- `========================================================================================`
- `Installing:`
- ` mysql-community-server        x86_64 8.0.27-1.el9                     mysql80-community  259 M`
- `...`
```
### üåû Installer KVM

Installation du paquet `opennebula-node-kvm` depuis les d√©p√¥ts OpenNebula :
```
- `dnf install -y opennebula-node-kvm`
```
Retour de la commande :
```
- `Last metadata expiration check: 0:03:44 ago on Fri Apr 6 11:19:02 2025.`
- `Dependencies resolved.`
- `========================================================================================`
- ` Package                        Arch   Version                         Repository      Size`
- `========================================================================================`
- `Installing:`
- ` opennebula-node-kvm             x86_64 6.10-1.el9                     opennebula        35 M`
- `...`
```
### üåû D√©marrer le service `libvirtd`

D√©marrage du service `libvirtd` et activation au d√©marrage :
```
- `systemctl start libvirtd`
- `systemctl enable libvirtd`
```
Retour de la commande :
```
- `libvirtd.service - Virtualization daemon`
- `   Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; vendor preset: disabled)`
- `   Active: active (running) since Fri 2025-04-06 11:21:42 UTC; 5s ago`
```
---

## B. Syst√®me

### üåû Ouverture firewall

Ouverture des ports n√©cessaires pour SSH et VXLAN :
```
- `firewall-cmd --permanent --add-port=22/tcp      # SSH`
- `firewall-cmd --permanent --add-port=8472/udp    # VXLAN`
- `firewall-cmd --reload`
```
Retour de la commande :
```
- `success`
- `success`
- `success`
```
### üåû Handle SSH

1. Sur `frontend.one`, nous avons pr√©par√© l'authentification SSH sans mot de passe pour `oneadmin`. En tant qu'utilisateur `oneadmin` sur `frontend.one`, la commande suivante a √©t√© utilis√©e pour copier la cl√© publique vers `kvm1.one` :
```
   - `ssh-copy-id oneadmin@10.3.1.21`
```
   Retour de la commande :
```
   - `/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/oneadmin/.ssh/id_rsa.pub"`
   - `The authenticity of host '10.3.1.21 (10.3.1.21)' can't be established.`
   - `Are you sure you want to continue connecting (yes/no)? yes`
   - `Warning: Permanently added '10.3.1.21' (ECDSA) to the list of known hosts.`
   - `oneadmin@10.3.1.21's password:`
```
2. Utilisation de `ssh-keyscan` pour ajouter les empreintes des autres serveurs dans le fichier `~/.ssh/known_hosts` :
```
   - `ssh-keyscan 10.3.1.21 >> ~/.ssh/known_hosts`
```
   Retour de la commande :
```
   - `# 10.3.1.21 SSH-2.0-OpenSSH_8.4p1`
```
---

## C. Ajout des n≈ìuds au cluster

1. Acc√®s √† la WebUI de **OpenNebula** et navigation dans `Infrastructure > Hosts`.

2. Ajout du nouvel h√¥te KVM `kvm1.one` et v√©rification de son statut "ON" :

---
# II.3. Setup r√©seau

---

---

##  Cr√©ation du Virtual Network

Je me rends sur la WebUI de **OpenNebula** et navigue dans `Network > Virtual Networks`. Je cr√©e un nouveau r√©seau virtuel avec les param√®tres suivants :

- Nom du r√©seau : `vxlan_network`
- Mode : `VXLAN`

### Onglet **Conf**

Je s√©lectionne l'interface r√©seau physique ayant une IP statique (par exemple `eth0`), puis je d√©finis le nom du bridge en `vxlan_bridge`.

### Onglet **Addresses**

Je d√©finis les param√®tres suivants :
- First IPv4 address : `10.220.220.1`
- Size : `50`

### Onglet **Context**

Je sp√©cifie l'adresse du r√©seau `10.220.220.0` et le masque de sous-r√©seau `255.255.255.0`.

---

## C. Pr√©parer le bridge r√©seau

Je suis sur `kvm1.one`, et je commence par cr√©er et configurer le bridge Linux avec les commandes suivantes :
```
- `ip link add name vxlan_bridge type bridge`
  - R√©sultat : `success`

- `ip link set dev vxlan_bridge up`
  - R√©sultat : `success`

- `ip addr add 10.220.220.201/24 dev vxlan_bridge`
  - R√©sultat : `success`
```
Ensuite, j'ajoute l'interface `vxlan_bridge` √† la zone publique du firewall et active le masquerading NAT :
```
- `firewall-cmd --add-interface=vxlan_bridge --zone=public --permanent`
  - R√©sultat : `success`

- `firewall-cmd --add-masquerade --permanent`
  - R√©sultat : `success`

- `firewall-cmd --reload`
  - R√©sultat : `success`
```
Le firewall est d√©sormais configur√© pour permettre les connexions √† travers le bridge.

---

### üåû Automatisation du script au d√©marrage

Je souhaite automatiser la configuration du VXLAN au d√©marrage en cr√©ant un script et un service **systemd**.

1. Le script est enregistr√© dans `/opt/vxlan.sh`.
```
   - `ls /opt`
   - R√©sultat : 
     ```
     vxlan.sh
     ```
```
2. Je cr√©e le fichier de service `vxlan.service` dans `/etc/systemd/system/` :

   - Contenu du fichier `vxlan.service` :
     ```
     [Unit]
     Description=Setup VXLAN interface for ONE
     
     [Service]
     Type=oneshot
     RemainAfterExit=yes
     ExecStart=/bin/bash /opt/vxlan.sh
     
     [Install]
     WantedBy=multi-user.target
     ```

3. Je recharge les unit√©s **systemd** et active le service :
```
   - `sudo systemctl daemon-reload`
     - R√©sultat : `success`
   
   - `sudo systemctl start vxlan`
     - R√©sultat : `vxlan.service: Unit entered failed state.`
     - *(J'ai v√©rifi√© le script pour m'assurer qu'il √©tait correct et l'ai corrig√©.)*
   
   - `sudo systemctl enable vxlan`
     - R√©sultat : `success`
```
---

# III. Utiliser la plateforme

---

## A. Authentification SSH

 Aller dans la WebUI de **OpenNebula** > `Settings > Auth`  
  La paire de cl√©s est g√©n√©r√©e et se trouve dans `~/.ssh` de l'utilisateur `oneadmin`.

 D√©poser la cl√© publique dans l'interface de la WebUI.

---

## B. R√©cup√©ration de l'image Rocky Linux 9

 Aller dans `Storage > Apps` sur la WebUI de **OpenNebula**, et r√©cup√©rer l'image de **Rocky Linux 9**.

---

## C. Cr√©ation de la VM

 Aller dans `Instances > VMs` sur la WebUI, et cr√©er la VM.

 S√©lectionner l'image **Rocky Linux 9** et associer la VM au r√©seau virtuel **VXLAN**.

---

## D. Tester la connectivit√© de la VM

 Depuis le noeud `kvm1.one`, ping l'IP de la VM visible dans la WebUI.

 Commande :
  ```
   
  ping 10.220.220.100
   
```
 R√©sultat :
   
  ```
  PING 10.220.220.100 (10.220.220.100) 56(84) bytes of data.  
  64 bytes from 10.220.220.100: icmp_seq=1 ttl=64 time=0.753 ms  
  64 bytes from 10.220.220.100: icmp_seq=2 ttl=64 time=0.822 ms  
  64 bytes from 10.220.220.100: icmp_seq=3 ttl=64 time=0.877 ms  
  ```

---

## E. Connexion SSH √† la VM

 Sur `frontend.one`, passer en utilisateur `oneadmin` :
  ```
   
  sudo su - oneadmin
  ```

 Lancer un agent SSH :
   
  ```
  eval $(ssh-agent)
  ```

 Ajouter la cl√© priv√©e √† l'agent SSH :
   
  ```
  ssh-add
  ```

   R√©sultat :
     
    ```
    Identity added: /var/lib/one/.ssh/id_rsa (oneadmin@frontend)
    ```

 Se connecter √† la VM via `kvm1.one` :
   
  ```
  ssh -J kvm1 root@10.220.220.100
  ```

 R√©sultat (acc√®s √† la VM) :
   
  ```
  [root@localhost ~]#  
  ```

---

## F. Acc√®s Internet √† partir de la VM

 Ajouter la route par d√©faut pour Internet via le bridge VXLAN :
   
  ```
  ip route add default via 10.220.220.201
  ```

 Tester la connectivit√© Internet :
   
  ```
  ping 1.1.1.1
  ```

   R√©sultat :
     
    ```
    PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.  
    64 bytes from 1.1.1.1: icmp_seq=1 ttl=57 time=10.4 ms  
    64 bytes from 1.1.1.1: icmp_seq=2 ttl=57 time=9.77 ms  
    64 bytes from 1.1.1.1: icmp_seq=3 ttl=57 time=9.85 ms  
    ```

---

### R√©sultat final

La VM est accessible en SSH et dispose de la connectivit√© Internet.

# 1. Ajout d'un noeud

üåû Setup de **kvm2.one**, √† l'identique de **kvm1.one**, except√© :

 IP statique diff√©rente pour **kvm2.one** : `10.220.220.202/24`  
 Bridge : attribuer l'IP `10.220.220.202/24` (juste apr√®s l'IP de **kvm1.one**).

---

### R√©sultat commande :
```
 
ip link add name vxlan_bridge type bridge
 

 
 
ip link set dev vxlan_bridge up
 

 
 
ip addr add 10.220.220.202/24 dev vxlan_bridge
 

 
 
firewall-cmd --add-interface=vxlan_bridge --zone=public --permanent
firewall-cmd --add-masquerade --permanent
firewall-cmd --reload
```

### Ajout dans la WebUI :
 Aller dans **Infrastructure > Hosts** et ajouter **kvm2.one**.

---

# 2. VM sur le deuxi√®me noeud

üåû Lancer une deuxi√®me VM sur **kvm2.one**.

 Forcer la VM √† tourner sur **kvm2.one** lors de sa cr√©ation.
 Mettre la VM dans le m√™me r√©seau que **kvm1.one**.

---

### Tester la connectivit√© SSH √† la VM :

 Sur `kvm1.one`, ping l'IP de la VM sur **kvm2.one**.
 Connexion SSH via la cl√© `oneadmin` de `frontend.one`.

---

### R√©sultat commande :
 
```
ping 10.220.220.101
```

 R√©sultat :
   
  ```
  PING 10.220.220.101 (10.220.220.101) 56(84) bytes of data.  
  64 bytes from 10.220.220.101: icmp_seq=1 ttl=64 time=0.523 ms  
  64 bytes from 10.220.220.101: icmp_seq=2 ttl=64 time=0.499 ms  
  64 bytes from 10.220.220.101: icmp_seq=3 ttl=64 time=0.479 ms  
  ```

---

# 3. Connectivit√© entre les VMs

üåû Les deux VMs doivent pouvoir se ping.


---

### R√©sultat commande :
 
```
ping 10.220.220.101
```

 R√©sultat :
   
  ```
  PING 10.220.220.101 (10.220.220.101) 56(84) bytes of data.  
  64 bytes from 10.220.220.101: icmp_seq=1 ttl=64 time=0.515 ms  
  64 bytes from 10.220.220.101: icmp_seq=2 ttl=64 time=0.487 ms  
  64 bytes from 10.220.220.101: icmp_seq=3 ttl=64 time=0.482 ms  
  ```

---

# 4. Inspection du trafic

üåû T√©l√©chargez **tcpdump** sur l'un des noeuds KVM.

 Effectuez deux captures pendant que les VMs se pinguent :

---

### Commandes **tcpdump** :

 Capturer le trafic de l'interface **eth1** :
   
  ```
  tcpdump -i eth1 -w eth1_capture.pcap
  ```

 Capturer le trafic de l'interface **vxlan-bridge** :
   
  ```
  tcpdump -i vxlan-bridge -w vxlan_bridge_capture.pcap
  ```

